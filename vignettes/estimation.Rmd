---
title: "Model estimation"
author: David Selby
date: August 2022
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Model estimation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Here we implement the AOP(1) model of Mo Li and QiQi Lu in the paper https://doi.org/10.1002/env.2752, published in _Environmetrics_ in 2022.
The paper proposes a latent Gaussian process model for ordinal data.
And several CUSUM statistics for detecting changepoints.

We minimize
\[Q(\boldsymbol\theta) = \sum_{t=1}^n \sum_{k=1}^K (Y_{t,k} - \mathbb{E}[Y_{t,k}])^2,\]
where
\[\mathbb{E}[Y_{tk}] = \Phi(c_k - \mu_t) - \Phi(c_{k-1} - \mu_t).\]

The latent variable $Z_t$ is assumed to have unit variance so that the sum of squares objective function $Q$ does not depend on the autocorrelation parameter $\rho$.

We use Newton's method with a tolerance of $10^{-5}$.
This is implemented in the `nlm()` function in R.
Starting values for $\alpha_1, A, D, \Delta$ are set to 0.
Starting values for $\alpha_0$ and thresholds $c_2,\dots,c_{K-1}$ are $\alpha_0 = -\Phi^{-1}(p_1)$ and $c_k=-\Phi^{-1}\left(\sum_{j=1}^k p_j\right) + \alpha_0, where $p_j$ is the sample proportion of times that $Y_t$ lies in category $j$.

Recall the model definition
\[
\mu_t = \alpha_0 + \alpha_1 \frac{t}{n} + s_t + \Delta I_{(t \geq \tau)},
\]
where
\[s_t = A \cos\left(\frac{2\pi}{T} t\right) + D \sin \left(\frac{2\pi}{T}t\right)\]
and we have parameter vector $\boldsymbol\theta = (c_2, \dots, c_{K-1}, \alpha_0, \alpha_1, A, D, \Delta)$.

## Simulation

```{r}
local({
  n <- 10000
  #  K <- 3
  L <- 3
  alpha0 <- 0.4307
  alpha1 <- 0.1
  A <- 0.3
  D <- -0.5
  rho <- 0.5
  t <- 1:n
  s <- A * cos(2 * pi / L * t) + D * sin(2 * pi / L * t)
  mu <- alpha0 + alpha1 * t / n + s # no changepoints yet
  Z <- rnorm(n, mu, sqrt(1 - rho^2))
  for (i in 2:n)
    Z[i] <- Z[i] + rho * (Z[i - 1] - mu[i - 1])
  Y <- findInterval(Z, c(0, 0.8615)) + 1
  Y
}) -> Y

library(ordinalchange)
seq_estimation(Y, tau = 5000, K = 3, L = 3)
# ignore the last element of theta since we don't have any changepoints
# should be (0.8615, 0.4307, 0.1, 0.3, -0.5, ___)
# and rho should be 0.5
```

```{r}
local({
  n <- 10000
  #  K <- 3
  L <- 3
  alpha0 <- 0.4307
  alpha1 <- 0.1
  A <- 0.3
  D <- -0.5
  rho <- -0.5
  t <- 1:n
  s <- A * cos(2 * pi / L * t) + D * sin(2 * pi / L * t)
  mu <- alpha0 + alpha1 * t / n + s # no changepoints yet
  Z <- rnorm(n, mu, sqrt(1 - rho^2))
  for (i in 2:n)
    Z[i] <- Z[i] + rho * (Z[i - 1] - mu[i - 1])
  Y <- findInterval(Z, c(0, 0.8615)) + 1
  Y
}) -> Y

seq_estimation(Y, tau = 5000, K = 3, L = 3)
# as above but with rho = -0.5
```

CUSUM test statistics

```{r}
changepoint_detection <- function(Y) {
  n <- length(Y)
  max_M <- -Inf
  best_changepoint <- NA
  K <- 3 ### temporary; to be inferred
  for (t in seq(2, length(Y) - 1, by = 500)) { # 2:(length(Y) - 1)) {
    message('Fitting model for timepoint tau = ', t)
    model <- seq_estimation(Y, tau = t, K = 3, L = 3)
    theta <- model$theta
    rho <- model$rho$par
    mu <- ordinalchange:::mu(alpha0 = theta[K-1],
                              alpha1 = theta[K],
                              A = theta[K + 1],
                              D = theta[K + 2],
                              Delta = theta[K + 3],
                              Y, t, L = 3)
    X_tilde <- ordinalchange:::X_tilde(Y, mu, cutpoints = c(-Inf, 0, theta[1:(K-2)], Inf))
    eta <- sqrt(ordinalchange:::bartlett_eta(X_tilde))
    test_M <- abs(sum(X_tilde[1:t]) - t / n * sum(X_tilde)) / sqrt(n)
    if (test_M > max_M) {
      message('\tBetter changepoint found: tau = ', t, ' with M = ', test_M)
      max_M <- test_M
      best_changepoint <- t
    }
  }
  c(tau = best_changepoint, M = max_M)
}
```
